# Introduzione

Un sistema di calcolo viene astrattato, in ordine di complessità, in più livelli logici partendo dal livello più basso:

- il silicio e come vengono organizzati i chip;

- reti logiche, realizzate con la sottostante tecnologia (logica booleana), e come realizzare logiche complesse
usando solo logica booleana;

- progetto della CPU e relativo ISA che rappresenta l'interfaccia tra software e hardware.

L'ISA è un elenco di tutte le istruzioni che la CPU è in grado di eseguire, quindi delle sue capacità. Inoltre ci danno
indicazioni su come vengono eseguite, e anche: quanto è grande il register file, la grandezza del machine word e come
codificare un'istruzione in una sequenza di bit.

CUDA, OpenCV sono _programming model_ derivati per la programmazione parallela.

## Obiettivi

> Trasformare il codice, da un linguaggio a un altro. Il compito del compilatore è quello di abbassare il livello di
astrazione da un linguaggio di alto livello a un linguaggio di basso livello (assembly).

Il **compiler** è quel pezzo di della toolchain che porta da un linguaggio di alto livello all'assembly. È il primo di una
serie di tool, che fa parte di una _toolchain_, che vengono applicati in catena per produrre l'eseguibile finale.

La fase successiva è l'uso dell'assembler che partendo dal codice in assembly genera un file oggetto, ad esempio in formato,
ELF che contiene dati (statici, globali che sono già stati inizializzati), istruzioni, simboli di debug e altro per
l'esecuzione.

Per modularità ci si basa su librerie, ovvero porzioni di codice già scritte e magari anche compilate. Separare i tool
del compilatore permette l'uso di librerie, e in questo caso si fa uso del linker.

Potremmo avere anche del codice di _startup_, in C abbiamo il main che è un entry point, ma che in realtà non è la prima
funzione eseguita. Nello startup code vengono fatte tutta una serie di operazioni di inizializzazione di base.

Ho anche un _linker script_ che mi permette di specificare dove posizionare un codice o un certo tipo di dato.
Ad esempio se ho una SRAM veloce posso posizionare alcune informazioni qui, oppure mettere un segmento istruzioni in
memoria in sola lettura.

L'eseguibile prodotto dal linker può essere ulteriormente processato, che può essere passato a `objcopy` che produce il
file binario vero e proprio.

Procedendo in senso inverso si può usare `objdump` per fare _disassembling_, ovvero produrre assembly da un eseguibile.

### Ottimizzazione

> La seconda funzione è quello di migliorare il codice, ovvero ottimizzare.

L'interpretazione di ottimizzazione può essere soggetta a interpretazione, in base alla metrica di riferimento: di solito
si vuole eseguire il codice il più velocemente possibile, oppure si può impostare come metrica obiettivo la diminuzione
dello spazio occupato dal codice, oppure la migliore efficienza energetica, o che si sfruttino delle caratteristiche
architetturali.

## Evoluzione

Legge di Moore e problema della miniaturizzazione: riducendo la dimensione dei transistor, e quindi dei chip, aumenta
la capacità dissipativa richiesta.

> Ogni decennio possiamo considerare una nuova categoria di computer. Gordon Bell

> Ogni 18 mesi il numero di transistor che riesco a stampare raddoppia. Gordon Moore (fondatore di Intel)

Quindi ogni 18 mesi mi trovo con un dispositivo di egual potenza ma di dimensioni dimezzate, e quindi costo ridotto,
oppure con un dispositivo che raddoppia la sua potenza.

La potenza richiesta aumenta e quindi anche il calore che bisogna gestire. All'inizio degli anni 2000 non si riesce
a dissipare più calore di così.

Non riesco ad alzare più la frequenza di clock, ma inizia l'era del multicore. L'idea di base è sfruttare tanti core
con frequenze più basse, piuttosto che uno solo con frequenze crescenti.

Il numero di transistor aumenta, ma la frequenza del single core non aumenta, quindi le performance delle applicazioni
sequenziali non aumentano. È questo il problema principale, bisogna rieducare i programmatori per programmare in
parallelo.

Le tecniche di programmazione parallela nascono nell'ambito del supercomputing e ultimamente questi programming models
approdano alla massa.

E con tutte le librerie e il codice fin'ora scritto come dobbiamo fare? All'inizio degli anni 2000 si cerca di comprendere
come un programma scritto per single core possa eseguire in multicore, e come un compilatore possa aiutarci in ciò.

## Compilatori

Da un lato nascono dei compilatori _auto-parallelizzanti_ e anche GCC e LLVM hanno dei potenti strumenti per fare detection
e trasformazione del codice in codice multithreaded. Putroppo non si è arrivata a una soluzione "magica".

È difficile capire dove potrebbe trovarsi il parallelismo in un programma, e in una categoria di programmi si riesce a fare
chiamata _embarassingly parallel_.

In questi tipi di programmi abbiamo dei loop con manipolazione di strutture dati regolari in cui ogni ciclo è indipendente.

Ma nascono anche dei _parallel programming models_, ovvero il compilatore offre delle interfacce e dei costrutti per
supportare facilmente il parallelismo. Ad esempio CUDA estende il C/C++ con un po' di sintassi per specificare il
comportamento parallelo del sistema, oppure OpenMP.

CUDA -> parallelismo massiccio su GPGPU.

OpenMP -> compilatore parallelo che supporta C/C++ e Fortran (perché nel calcolo scientifico si usano ancora numerose
routine scritte in Fortran). Il codice viene scritto nel linguaggio scelto e si aggiungono delle annotazioni con delle
pragma.

```c
#pragma omp parallelfor
for (i=0; i<N; i++)
    { ... }
```

per trasformare questo codice in parallelo dobbiamo usare delle primitive del SO (thread) e si usano librerie come `pthread`.

Si prende il codice, si fa _outrunning_ creando una funzione parallela che esegue quel codice e si fa puntare `pthread_ a
questa nuova funzione. Anche i dati da elaborare devono essere correttamente impacchettati.

> Implementare un programming model vuol dire estendere un linguaggio con una sintassi che supporti il mio modello, ed
estendere il compilatore per interfacciare le librerie di supporto.

Più che librerie di supporto è meglio parlare di _runtime environments_, ovvero librerie che si linkano e contengono
informazioni sullo stato del sistema. Il runtime environment si interfaccia poi con _pthread_.

Servono ad agevolare questa transizione.

## Eterogeneità architetturale

Non solo siamo passati da single core a multi core omogeneo, ovvero replico le CPU (lo stesso identico processore) all'interno
dello stesso package, ma anche al multi core eterogeneo.

Sui computer moderni vengono eseguiti carichi di lavoro delle diverse tipologie, che possono essere eseguiti in modo efficiente
da dei sistemi di calcolo dedicati velocissimi per fare quel tipo di calcolo.

La prima tipologia che approda è la GPU che nasce per fare calcoli di trigonometria, molto velocemente, oltre a shading, ray
tracing e tutte le tecniche utilizzate per il rendering di ambienti tridimensionali.

Nel corso degli anni le GPU sono diventate GPGPU, ovvero general purpose GPU perché eseguono in modo efficiente calcolo
parallelo general purpose e non solo grafica. Per questo le GPU Nvidia (ad esempio) vengono usate per i più disparati
motivi.

I vari acceleratori possono essere in diversi chip discreti oppure in un **System on Chip**. Ultimamente sono arrivati
acceleratori per reti neurali e calcolo matriciale (tensor processor unit).

## Metriche

La performance è:

$$
\text{performance} = { 1 \over \text{execution time}}
$$

mentre l'execution time:

$$
\text{execution time} = {\text{instruction count} \cdot CPI \over \text{frequency}}
$$

In teoria frequency e CPI sono parametri di design, quindi il programmatore non lo può modificare, anche se in base
a come scelego le istruzioni posso migliorare quella voce. I branch hanno un CPI pià alto perché devo considerare possibili
misprediction, mentre le load/store hanno CPI più alto perché accedono alla memoria.

Per migliorare il CPI si può minimizzare il numero di istruzioni (per ridurre l'instruction count) oppure rimpiazzare
operazioni costose con altre più semplici:

```
mul s0, s2, 8
```

può diventare

```
slli s0, s2, 3
```
